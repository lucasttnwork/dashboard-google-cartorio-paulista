# Tarefa 2: FASE 2 - Sistema de Scraping Automático

## Status: ⏳ PENDING
## Prioridade: High
## Data de Criação: 2025-01-09

## Descrição
Implementar coleta automática de dados do Google Business Profile com agendamento de hora em hora.

## Detalhes Técnicos
- Sistema de scraping com Playwright
- Agendamento automático (cron)
- Processamento e limpeza de dados
- Armazenamento no Supabase
- Tratamento de erros e retries

## Requisitos Funcionais

### 2.1 ⏳ Configurar Playwright para scraping GBP
**Status**: ⏳ PENDING
**Descrição**: Setup da ferramenta de automação web para Google Business Profile

**Tarefas Técnicas**:
- Instalar e configurar Playwright
- Criar scripts de scraping específicos para GBP
- Implementar navegação headless estável
- Capturar dados de avaliações (rating, comentário, data, nome)
- Implementar tratamento de CAPTCHA e rate limiting
- Sistema de retry para falhas temporárias

**Critérios de Aceitação**:
- ✅ Playwright instalado e configurado
- ✅ Script básico de scraping funcional
- ✅ Captura de pelo menos 10 avaliações de teste
- ✅ Tratamento básico de erros implementado

### 2.2 ⏳ Implementar coleta de avaliações
**Status**: ⏳ PENDING
**Descrição**: Sistema completo de extração e estruturação de dados

**Estrutura de Dados**:
```typescript
interface ReviewData {
  review_id: string
  rating: number (1-5)
  comment: string
  reviewer_name: string
  create_time: string (ISO 8601)
  collection_source: string ("google")
  collaborator_mentions: string[] // nomes identificados
}
```

**Funcionalidades**:
- Parsing preciso de ratings (estrelas para números)
- Extração completa de comentários longos
- Captura de metadados (data, nome do avaliador)
- Identificação automática da fonte (Google)
- Estruturação consistente dos dados coletados

### 2.3 ⏳ Sistema de deduping e validação
**Status**: ⏳ PENDING
**Descrição**: Evitar duplicatas e garantir integridade dos dados

**Estratégias de Deduping**:
- Hash-based deduplication (SHA-256 do conteúdo)
- Comparação por data + nome + rating
- Cache de reviews já processadas
- Validação de dados obrigatórios

**Validações**:
- Rating deve ser 1-5
- Comentário não pode ser vazio
- Data deve ser válida e não futura
- Nome do avaliador presente
- Formato de dados consistente

### 2.4 ⏳ Análise de texto para menções de colaboradores
**Status**: ⏳ PENDING
**Descrição**: Processamento NLP para identificar menções a colaboradores

**Técnicas de Processamento**:
- Regex patterns para nomes conhecidos
- Fuzzy matching para variações (Ana/Ana Sophia)
- Case insensitive matching
- Remoção de acentos e caracteres especiais

**Colaboradores Conhecidos**:
- Ana Sophia
- Karen Figueiredo
- Letícia Andreza
- Pedro Santos
- Maria Oliveira
- Kaio Gomes

### 2.5 ⏳ Agendamento automático (cron job)
**Status**: ⏳ PENDING
**Descrição**: Sistema de execução programada a cada hora

**Implementação**:
- Node-cron para agendamento
- Execução a cada hora (:00 de cada hora)
- Logs detalhados de cada execução
- Sistema de alertas para falhas
- Dashboard de status do scraping
- Possibilidade de execução manual

**Monitoramento**:
- Status da última execução
- Número de reviews coletadas
- Tempo de processamento
- Taxa de sucesso/falha
- Alertas automáticos por email/Slack

## Dependências
- Tarefa 1: Infraestrutura Core (especialmente Supabase)

## Critérios de Aceitação da Fase
- ✅ Sistema coleta automaticamente a cada hora
- ✅ Pelo menos 95% de uptime do scraping
- ✅ Dados armazenados corretamente no Supabase
- ✅ Menções de colaboradores identificadas corretamente
- ✅ Dashboard mostra status do scraping em tempo real

## Riscos e Mitigações
- **Bloqueio do Google**: Implementar delays aleatórios, user agents variados
- **Mudanças no layout do GBP**: Monitoramento contínuo e alertas automáticos
- **Rate limiting**: Sistema de backoff exponencial
- **Dados corrompidos**: Validações rigorosas e limpeza automática

## Observações Técnicas
- Usar proxies residenciais para evitar detecção
- Implementar circuit breaker pattern
- Logs estruturados para debugging
- Métricas detalhadas para monitoramento
- Backup automático dos dados coletados
